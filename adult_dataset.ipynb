{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667d7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pystan\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from argparse import ArgumentParser, ArgumentTypeError\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0939452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.430759</td>\n",
       "      <td>0.731806</td>\n",
       "      <td>0.632047</td>\n",
       "      <td>0.464143</td>\n",
       "      <td>0.591700</td>\n",
       "      <td>0.457371</td>\n",
       "      <td>0.861222</td>\n",
       "      <td>0.673772</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.023619</td>\n",
       "      <td>0.413652</td>\n",
       "      <td>0.915538</td>\n",
       "      <td>0.245684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.148674</td>\n",
       "      <td>0.443034</td>\n",
       "      <td>0.159920</td>\n",
       "      <td>0.498729</td>\n",
       "      <td>0.463801</td>\n",
       "      <td>0.498196</td>\n",
       "      <td>0.345726</td>\n",
       "      <td>0.468848</td>\n",
       "      <td>0.077033</td>\n",
       "      <td>0.107767</td>\n",
       "      <td>0.121847</td>\n",
       "      <td>0.278089</td>\n",
       "      <td>0.430506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.411111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age     workclass  education-num  marital-status  \\\n",
       "count  15060.000000  15060.000000   15060.000000    15060.000000   \n",
       "mean       0.430759      0.731806       0.632047        0.464143   \n",
       "std        0.148674      0.443034       0.159920        0.498729   \n",
       "min        0.188889      0.000000       0.062500        0.000000   \n",
       "25%        0.311111      0.000000       0.562500        0.000000   \n",
       "50%        0.411111      1.000000       0.625000        0.000000   \n",
       "75%        0.533333      1.000000       0.812500        1.000000   \n",
       "max        1.000000      1.000000       1.000000        1.000000   \n",
       "\n",
       "         occupation  relationship          race           sex  capital-gain  \\\n",
       "count  15060.000000  15060.000000  15060.000000  15060.000000  15060.000000   \n",
       "mean       0.591700      0.457371      0.861222      0.673772      0.011203   \n",
       "std        0.463801      0.498196      0.345726      0.468848      0.077033   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      1.000000      1.000000      0.000000   \n",
       "75%        1.000000      1.000000      1.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       capital-loss  hours-per-week  native-country        salary  \n",
       "count  15060.000000    15060.000000    15060.000000  15060.000000  \n",
       "mean       0.023619        0.413652        0.915538      0.245684  \n",
       "std        0.107767        0.121847        0.278089      0.430506  \n",
       "min        0.000000        0.010101        0.000000      0.000000  \n",
       "25%        0.000000        0.404040        1.000000      0.000000  \n",
       "50%        0.000000        0.404040        1.000000      0.000000  \n",
       "75%        0.000000        0.454545        1.000000      0.000000  \n",
       "max        1.000000        1.000000        1.000000      1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Adult_dataset():\n",
    "    \n",
    "    def __init__(self, train_file='adult_dataset/adult.data', \n",
    "                       test_file='adult_dataset/adult.test'):\n",
    "        self.cols = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', \n",
    "                     'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "                     'hours-per-week', 'native-country', 'salary']\n",
    "        self.train_df = pd.read_csv(train_file, names=self.cols)\n",
    "        self.test_df = pd.read_csv(test_file, names=self.cols)\n",
    "        \n",
    "        # Preprocessing \n",
    "        self.train_df = self.preprocessing(self.train_df)\n",
    "        self.test_df = self.preprocessing(self.test_df)\n",
    "        \n",
    "    \n",
    "    def preprocessing(self, df):\n",
    "        # Cols to drop\n",
    "        df = df.drop(columns=['fnlwgt', 'education'])\n",
    "        \n",
    "        # Remove rows with unknown data\n",
    "        df = df.replace(' ?', np.NaN)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # Convert categorical to int \n",
    "        df['salary'] = df['salary'].replace(' <=50K.', 0).replace(' >50K.', 1)\n",
    "        df['salary'] = df['salary'].replace(' <=50K', 0).replace(' >50K', 1)\n",
    "        df['workclass'] = df['workclass'].apply(lambda x: 1 if x==' Private' else 0)\n",
    "        df['marital-status'] = df['marital-status'].apply(lambda x: 1 if x==' Married-civ-spouse' else 0) \n",
    "        df['relationship'] = df['relationship'].apply(lambda x: 1 if x in (' Husband', ' Wife') else 0) \n",
    "        occupation_mapping = {\n",
    "            \" Exec-managerial\": 1,\n",
    "            \" Craft-repair\": 0,\n",
    "            \" Prof-specialty\": 1,\n",
    "            \" Sales\": 1,\n",
    "            \" Adm-clerical\": 1,\n",
    "            \" Other-service\": 0.5,\n",
    "            \" Machine-op-inspct\": 0,\n",
    "            \" Transport-moving\": 0,\n",
    "            \" Handlers-cleaners\": 0,\n",
    "            \" Tech-support\": 1,\n",
    "            \" Farming-fishing\": 0,\n",
    "            \" Protective-serv\": 0,\n",
    "            \" Priv-house-serv\": 0,\n",
    "            \" Armed-Forces\": 0\n",
    "        }\n",
    "        df['occupation'] = df['occupation'].apply(lambda x: occupation_mapping[x]) \n",
    "        df['race'] = df['race'].apply(lambda x: 1 if x==' White' else 0)\n",
    "        df['sex'] = df['sex'].apply(lambda x: 1 if x==' Male' else 0)\n",
    "        df['native-country'] = df['native-country'].apply(lambda x: 1 if x==' United-States' else 0)\n",
    "        \n",
    "        # Normalize between 0 and 1\n",
    "        df['age'] = df['age'] / df['age'].max()\n",
    "        df['education-num'] = df['education-num'] / df['education-num'].max()\n",
    "        df['capital-gain'] = df['capital-gain'] / df['capital-gain'].max()\n",
    "        df['capital-loss'] = df['capital-loss'] / df['capital-loss'].max()\n",
    "        df['hours-per-week'] = df['hours-per-week'] / df['hours-per-week'].max()\n",
    "        \n",
    "        return df\n",
    "\n",
    "adult_ds = Adult_dataset()\n",
    "adult_ds.test_df\n",
    "adult_ds.test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80589838",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fc49bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper class for statsmodels linear regression (more stable than SKLearn)\n",
    "class SM_LinearRegression():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        N = X.shape[0]\n",
    "        self.LRFit = sm.OLS(y, np.hstack([X, np.ones(N).reshape(-1, 1)]), hasconst=True).fit()\n",
    "\n",
    "    def predict(self, X):\n",
    "        N = X.shape[0]\n",
    "        return self.LRFit.predict(np.hstack([X, np.ones(N).reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0282dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Unfair Model predictions\n",
    "def Unfair_Model_Replication(train_df, test_df):\n",
    "    lr_unfair = SM_LinearRegression()\n",
    "    train_df_x = train_df.drop(columns=['salary']).to_numpy()\n",
    "    train_df_y = train_df['salary'].to_numpy()\n",
    "    lr_unfair.fit(train_df_x, train_df_y)\n",
    "    \n",
    "    test_df_x = test_df.drop(columns=['salary']).to_numpy()\n",
    "    test_df_y = test_df['salary'].to_numpy()\n",
    "    preds = lr_unfair.predict(test_df_x)\n",
    "\n",
    "    # Return Results:\n",
    "    return preds\n",
    "\n",
    "# Get the Unaware Model predictions\n",
    "def Unaware_Model_Replication(train_df, test_df, protected=['sex', 'race']):\n",
    "    lr_unfair = SM_LinearRegression()\n",
    "    train_df_x = train_df.drop(columns=['salary'] + protected).to_numpy()\n",
    "    train_df_y = train_df['salary'].to_numpy()\n",
    "    lr_unfair.fit(train_df_x, train_df_y)\n",
    "    \n",
    "    test_df_x = test_df.drop(columns=['salary'] + protected).to_numpy()\n",
    "    test_df_y = test_df['salary'].to_numpy()\n",
    "    preds = lr_unfair.predict(test_df_x)\n",
    "\n",
    "    # Return Results:\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e16c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Fair All/L3 Model Predictions\n",
    "def L3_Model_Replication(train_df, test_df, protected=['sex', 'age', 'race']):\n",
    "    train_df_protected = train_df[protected].to_numpy()\n",
    "    test_df_protected = test_df[protected].to_numpy()\n",
    "    train_df_y = train_df['salary'].to_numpy()\n",
    "    test_df_y = test_df['salary'].to_numpy()\n",
    "    \n",
    "    # workclass\n",
    "    linear_eps_w = SM_LinearRegression()\n",
    "    linear_eps_w.fit(train_df_protected, train_df['workclass'])\n",
    "    eps_w_train = train_df['workclass'].to_numpy() - linear_eps_w.predict(train_df_protected)\n",
    "    eps_w_test = test_df['workclass'].to_numpy() - linear_eps_w.predict(test_df_protected)\n",
    "    \n",
    "    # education-num\n",
    "    linear_eps_e = SM_LinearRegression()\n",
    "    linear_eps_e.fit(train_df_protected, train_df['education-num'])\n",
    "    eps_e_train = train_df['education-num'].to_numpy() - linear_eps_e.predict(train_df_protected)\n",
    "    eps_e_test = test_df['education-num'].to_numpy() - linear_eps_e.predict(test_df_protected)\n",
    "    \n",
    "    # occupation\n",
    "    linear_eps_o = SM_LinearRegression()\n",
    "    linear_eps_o.fit(train_df_protected, train_df['occupation'])\n",
    "    eps_o_train = train_df['occupation'].to_numpy() - linear_eps_o.predict(train_df_protected)\n",
    "    eps_o_test = test_df['occupation'].to_numpy() - linear_eps_o.predict(test_df_protected)\n",
    "    \n",
    "    # capital-gain\n",
    "    linear_eps_g = SM_LinearRegression()\n",
    "    linear_eps_g.fit(train_df_protected, train_df['capital-gain'])\n",
    "    eps_g_train = train_df['capital-gain'].to_numpy() - linear_eps_g.predict(train_df_protected)\n",
    "    eps_g_test = test_df['capital-gain'].to_numpy() - linear_eps_g.predict(test_df_protected)\n",
    "    \n",
    "    # capital-loss\n",
    "    linear_eps_l = SM_LinearRegression()\n",
    "    linear_eps_l.fit(train_df_protected, train_df['capital-loss'])\n",
    "    eps_l_train = train_df['capital-loss'].to_numpy() - linear_eps_l.predict(train_df_protected)\n",
    "    eps_l_test = test_df['capital-loss'].to_numpy() - linear_eps_l.predict(test_df_protected)\n",
    "    \n",
    "    # hours-per-week\n",
    "    linear_eps_h = SM_LinearRegression()\n",
    "    linear_eps_h.fit(train_df_protected, train_df['hours-per-week'])\n",
    "    eps_h_train = train_df['hours-per-week'].to_numpy() - linear_eps_h.predict(train_df_protected)\n",
    "    eps_h_test = test_df['hours-per-week'].to_numpy() - linear_eps_h.predict(test_df_protected)\n",
    "    \n",
    "\n",
    "    # predict on target using abducted latents\n",
    "    train_eps_stacked = np.hstack((eps_w_train.reshape(-1, 1), eps_e_train.reshape(-1, 1), \n",
    "                                   eps_o_train.reshape(-1, 1), eps_g_train.reshape(-1, 1), \n",
    "                                   eps_l_train.reshape(-1, 1), eps_h_train.reshape(-1, 1), \n",
    "                                   train_df['marital-status'].to_numpy().reshape(-1, 1), \n",
    "                                   train_df['relationship'].to_numpy().reshape(-1, 1),\n",
    "                                   train_df['native-country'].to_numpy().reshape(-1, 1)))\n",
    "    \n",
    "    test_eps_stacked = np.hstack((eps_w_test.reshape(-1, 1), eps_e_test.reshape(-1, 1), \n",
    "                                  eps_o_test.reshape(-1, 1), eps_g_test.reshape(-1, 1), \n",
    "                                  eps_l_test.reshape(-1, 1), eps_h_test.reshape(-1, 1), \n",
    "                                  test_df['marital-status'].to_numpy().reshape(-1, 1), \n",
    "                                  test_df['relationship'].to_numpy().reshape(-1, 1),\n",
    "                                  test_df['native-country'].to_numpy().reshape(-1, 1)))\n",
    "    smlr_L3 = SM_LinearRegression()\n",
    "    smlr_L3.fit(train_eps_stacked, train_df_y)\n",
    "\n",
    "    # predict on test epsilons\n",
    "    preds = smlr_L3.predict(test_eps_stacked)\n",
    "\n",
    "    # Return Results:\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57881ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfair_preds = Unfair_Model_Replication(adult_ds.train_df, adult_ds.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4e5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unaware_preds = Unaware_Model_Replication(adult_ds.train_df, adult_ds.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b49151",
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_preds = L3_Model_Replication(adult_ds.train_df, adult_ds.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad8656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfair RMSE: \t\t\t0.348\n",
      "FTU RMSE: \t\t\t0.349\n",
      "Level 3 (Fair Add) RMSE: \t0.352\n"
     ]
    }
   ],
   "source": [
    "print('Unfair RMSE: \\t\\t\\t%.3f' % np.sqrt(mean_squared_error(unfair_preds, adult_ds.test_df['salary'])))\n",
    "print('FTU RMSE: \\t\\t\\t%.3f' % np.sqrt(mean_squared_error(unaware_preds, adult_ds.test_df['salary'])))\n",
    "print('Level 3 (Fair Add) RMSE: \\t%.3f' % np.sqrt(mean_squared_error(l3_preds, adult_ds.test_df['salary'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfbee66",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd76d53",
   "metadata": {},
   "source": [
    "### Balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7624e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f15187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfair balanced accuracy: \t\t0.722\n",
      "FTU balanced accuracy: \t\t\t0.723\n",
      "Level 3 (Fair Add) balanced accuracy: \t0.716\n"
     ]
    }
   ],
   "source": [
    "print('Unfair balanced accuracy: \\t\\t%.3f' % balanced_accuracy_score(adult_ds.test_df['salary'], np.array(unfair_preds >= 0.5).astype(int)))\n",
    "print('FTU balanced accuracy: \\t\\t\\t%.3f' % balanced_accuracy_score(adult_ds.test_df['salary'], np.array(unaware_preds >= 0.5).astype(int)))\n",
    "print('Level 3 (Fair Add) balanced accuracy: \\t%.3f' % balanced_accuracy_score(adult_ds.test_df['salary'], np.array(l3_preds >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6556868",
   "metadata": {},
   "source": [
    "### Equalized odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b57760",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = adult_ds.test_df.copy()\n",
    "preds_df['unfair'] = np.array(unfair_preds >= 0.5).astype(int)\n",
    "preds_df['unaware'] = np.array(unaware_preds >= 0.5).astype(int)\n",
    "preds_df['l3'] = np.array(l3_preds >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f653a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_odds(preds_df, method='unfair', protected=['sex', 'binary_age', 'race']):\n",
    "    \n",
    "    preds_df['binary_age'] = preds_df['age'] >= 0.5\n",
    "    eq_odds = []\n",
    "    for attribute in protected:\n",
    "        eq_odd = preds_df.loc[(preds_df['salary']==1) & (preds_df[attribute]==0), method].mean() -  preds_df.loc[(preds_df['salary']==1) & (preds_df[attribute]==1), method].mean()\n",
    "        eq_odd += preds_df.loc[(preds_df['salary']==0) & (preds_df[attribute]==0), method].mean() -  preds_df.loc[(preds_df['salary']==0) & (preds_df[attribute]==1), method].mean()\n",
    "        eq_odds.append(np.abs(eq_odd))\n",
    "    return np.mean(eq_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca83037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfair Equalized Odds score: \t\t\t0.220\n",
      "FTU Equalized Odds score: \t\t\t0.147\n",
      "Level 3 (Fair Add) Equalized Odds score: \t0.083\n"
     ]
    }
   ],
   "source": [
    "print('Unfair Equalized Odds score: \\t\\t\\t%.3f' % equalized_odds(preds_df, method='unfair'))\n",
    "print('FTU Equalized Odds score: \\t\\t\\t%.3f' % equalized_odds(preds_df, method='unaware'))\n",
    "print('Level 3 (Fair Add) Equalized Odds score: \\t%.3f' % equalized_odds(preds_df, method='l3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edef024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
