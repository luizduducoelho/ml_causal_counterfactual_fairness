{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667d7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pystan\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from argparse import ArgumentParser, ArgumentTypeError\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0939452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>score_text</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5775.000000</td>\n",
       "      <td>5775.000000</td>\n",
       "      <td>5775.000000</td>\n",
       "      <td>5775.000000</td>\n",
       "      <td>5775.000000</td>\n",
       "      <td>5775.000000</td>\n",
       "      <td>5775.000000</td>\n",
       "      <td>5775.000000</td>\n",
       "      <td>5775.000000</td>\n",
       "      <td>5775.000000</td>\n",
       "      <td>5775.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.809697</td>\n",
       "      <td>0.361699</td>\n",
       "      <td>0.665628</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.091615</td>\n",
       "      <td>0.649004</td>\n",
       "      <td>0.331948</td>\n",
       "      <td>0.225022</td>\n",
       "      <td>0.453853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.392574</td>\n",
       "      <td>0.123715</td>\n",
       "      <td>0.471811</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.037525</td>\n",
       "      <td>0.030711</td>\n",
       "      <td>0.127973</td>\n",
       "      <td>0.477323</td>\n",
       "      <td>0.394510</td>\n",
       "      <td>0.335735</td>\n",
       "      <td>0.497909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.260417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sex          age         race  juv_fel_count  juv_misd_count  \\\n",
       "count  5775.000000  5775.000000  5775.000000    5775.000000     5775.000000   \n",
       "mean      0.809697     0.361699     0.665628       0.003316        0.007006   \n",
       "std       0.392574     0.123715     0.471811       0.023372        0.037525   \n",
       "min       0.000000     0.187500     0.000000       0.000000        0.000000   \n",
       "25%       1.000000     0.260417     0.000000       0.000000        0.000000   \n",
       "50%       1.000000     0.322917     1.000000       0.000000        0.000000   \n",
       "75%       1.000000     0.437500     1.000000       0.000000        0.000000   \n",
       "max       1.000000     1.000000     1.000000       1.000000        1.000000   \n",
       "\n",
       "       juv_other_count  priors_count  c_charge_degree   score_text  \\\n",
       "count      5775.000000   5775.000000      5775.000000  5775.000000   \n",
       "mean          0.006713      0.091615         0.649004     0.331948   \n",
       "std           0.030711      0.127973         0.477323     0.394510   \n",
       "min           0.000000      0.000000         0.000000     0.000000   \n",
       "25%           0.000000      0.000000         0.000000     0.000000   \n",
       "50%           0.000000      0.052632         1.000000     0.000000   \n",
       "75%           0.000000      0.131579         1.000000     0.500000   \n",
       "max           1.000000      1.000000         1.000000     1.000000   \n",
       "\n",
       "       v_score_text  two_year_recid  \n",
       "count   5775.000000     5775.000000  \n",
       "mean       0.225022        0.453853  \n",
       "std        0.335735        0.497909  \n",
       "min        0.000000        0.000000  \n",
       "25%        0.000000        0.000000  \n",
       "50%        0.000000        0.000000  \n",
       "75%        0.500000        1.000000  \n",
       "max        1.000000        1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Compas_dataset():\n",
    "    \n",
    "    def __init__(self, data_file='COMPAS_dataset/compas-scores-two-years.csv'):\n",
    "        self.cols = ['sex', 'age', 'race', 'juv_fel_count', \n",
    "                    'juv_misd_count', 'juv_other_count', \n",
    "                    'priors_count', 'c_charge_degree', \n",
    "                    'score_text', 'v_score_text', 'two_year_recid']\n",
    "        self.full_df = pd.read_csv(data_file, usecols=self.cols)\n",
    "        \n",
    "        # Preprocessing \n",
    "        self.full_df = self.preprocessing(self.full_df)\n",
    "        \n",
    "        # Split train and test\n",
    "        self.train_df, self.test_df = self.split_train_test(self.full_df)\n",
    "        \n",
    "    \n",
    "    def preprocessing(self, df):\n",
    "        \n",
    "        # Remove rows with unknown data\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # Convert categorical to int \n",
    "        df['sex'] = df['sex'].apply(lambda x: 0 if x=='Female' else 1)\n",
    "        df['c_charge_degree'] = df['c_charge_degree'].apply(lambda x: 0 if x=='M' else 1)\n",
    "        df['race'] = df['race'].apply(lambda x: 0 if x=='Caucasian' else 1)\n",
    "\n",
    "        # Normalize between 0 and 1\n",
    "        df['age'] = df['age'] / df['age'].max()\n",
    "        df['juv_fel_count'] = df['juv_fel_count'] / df['juv_fel_count'].max()\n",
    "        df['juv_misd_count'] = df['juv_misd_count'] / df['juv_misd_count'].max()\n",
    "        df['juv_other_count'] = df['juv_other_count'] / df['juv_other_count'].max()\n",
    "        df['priors_count'] = df['priors_count'] / df['priors_count'].max()\n",
    "        \n",
    "        score_mapping = {\n",
    "            \"Low\": 0,\n",
    "            \"Medium\": 0.5,\n",
    "            \"High\": 1\n",
    "        }\n",
    "        df['score_text'] = df['score_text'].apply(lambda x: score_mapping[x]) \n",
    "        df['v_score_text'] = df['v_score_text'].apply(lambda x: score_mapping[x]) \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def split_train_test(self, df, train_size=0.8):\n",
    "        msk = np.random.rand(len(df)) < train_size\n",
    "        train_df = df[msk]\n",
    "        test_df = df[~msk]\n",
    "        return train_df, test_df\n",
    "\n",
    "compas_ds = Compas_dataset()\n",
    "compas_ds.full_df\n",
    "compas_ds.train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80589838",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fc49bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper class for statsmodels linear regression (more stable than SKLearn)\n",
    "class SM_LinearRegression():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        N = X.shape[0]\n",
    "        self.LRFit = sm.OLS(y, np.hstack([X, np.ones(N).reshape(-1, 1)]), hasconst=True).fit()\n",
    "\n",
    "    def predict(self, X):\n",
    "        N = X.shape[0]\n",
    "        return self.LRFit.predict(np.hstack([X, np.ones(N).reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0282dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Unfair Model predictions\n",
    "def Unfair_Model_Replication(train_df, test_df, target=\"two_year_recid\"):\n",
    "    lr_unfair = SM_LinearRegression()\n",
    "    train_df_x = train_df.drop(columns=[target]).to_numpy()\n",
    "    train_df_y = train_df[target].to_numpy()\n",
    "    lr_unfair.fit(train_df_x, train_df_y)\n",
    "    \n",
    "    test_df_x = test_df.drop(columns=[target]).to_numpy()\n",
    "    test_df_y = test_df[target].to_numpy()\n",
    "    preds = lr_unfair.predict(test_df_x)\n",
    "\n",
    "    # Return Results:\n",
    "    return preds\n",
    "\n",
    "# Get the Unaware Model predictions\n",
    "def Unaware_Model_Replication(train_df, test_df, target=\"two_year_recid\", protected=['sex', 'race']):\n",
    "    lr_unfair = SM_LinearRegression()\n",
    "    train_df_x = train_df.drop(columns=[target] + protected).to_numpy()\n",
    "    train_df_y = train_df[target].to_numpy()\n",
    "    lr_unfair.fit(train_df_x, train_df_y)\n",
    "    \n",
    "    test_df_x = test_df.drop(columns=[target] + protected).to_numpy()\n",
    "    test_df_y = test_df[target].to_numpy()\n",
    "    preds = lr_unfair.predict(test_df_x)\n",
    "\n",
    "    # Return Results:\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e16c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Fair All/L3 Model Predictions\n",
    "def L3_Model_Replication(train_df, test_df, target=\"two_year_recid\", protected=['sex', 'race']):\n",
    "    train_df_protected = train_df[protected].to_numpy()\n",
    "    test_df_protected = test_df[protected].to_numpy()\n",
    "    train_df_y = train_df[target].to_numpy()\n",
    "    test_df_y = test_df[target].to_numpy()\n",
    "    \n",
    "    # juv_fel_count\n",
    "    linear_eps_w = SM_LinearRegression()\n",
    "    linear_eps_w.fit(train_df_protected, train_df['juv_fel_count'])\n",
    "    eps_w_train = train_df['juv_fel_count'].to_numpy() - linear_eps_w.predict(train_df_protected)\n",
    "    eps_w_test = test_df['juv_fel_count'].to_numpy() - linear_eps_w.predict(test_df_protected)\n",
    "    \n",
    "    # juv_misd_count\n",
    "    linear_eps_e = SM_LinearRegression()\n",
    "    linear_eps_e.fit(train_df_protected, train_df['juv_misd_count'])\n",
    "    eps_e_train = train_df['juv_misd_count'].to_numpy() - linear_eps_e.predict(train_df_protected)\n",
    "    eps_e_test = test_df['juv_misd_count'].to_numpy() - linear_eps_e.predict(test_df_protected)\n",
    "    \n",
    "    # juv_other_count\n",
    "    linear_eps_o = SM_LinearRegression()\n",
    "    linear_eps_o.fit(train_df_protected, train_df['juv_other_count'])\n",
    "    eps_o_train = train_df['juv_other_count'].to_numpy() - linear_eps_o.predict(train_df_protected)\n",
    "    eps_o_test = test_df['juv_other_count'].to_numpy() - linear_eps_o.predict(test_df_protected)\n",
    "    \n",
    "    # priors_count\n",
    "    linear_eps_g = SM_LinearRegression()\n",
    "    linear_eps_g.fit(train_df_protected, train_df['priors_count'])\n",
    "    eps_g_train = train_df['priors_count'].to_numpy() - linear_eps_g.predict(train_df_protected)\n",
    "    eps_g_test = test_df['priors_count'].to_numpy() - linear_eps_g.predict(test_df_protected)\n",
    "    \n",
    "    # c_charge_degree\n",
    "    linear_eps_l = SM_LinearRegression()\n",
    "    linear_eps_l.fit(train_df_protected, train_df['c_charge_degree'])\n",
    "    eps_l_train = train_df['c_charge_degree'].to_numpy() - linear_eps_l.predict(train_df_protected)\n",
    "    eps_l_test = test_df['c_charge_degree'].to_numpy() - linear_eps_l.predict(test_df_protected)\n",
    "    \n",
    "    # score_text\n",
    "    linear_eps_h = SM_LinearRegression()\n",
    "    linear_eps_h.fit(train_df_protected, train_df['score_text'])\n",
    "    eps_h_train = train_df['score_text'].to_numpy() - linear_eps_h.predict(train_df_protected)\n",
    "    eps_h_test = test_df['score_text'].to_numpy() - linear_eps_h.predict(test_df_protected)\n",
    "    \n",
    "    # v_score_text\n",
    "    linear_eps_v = SM_LinearRegression()\n",
    "    linear_eps_v.fit(train_df_protected, train_df['v_score_text'])\n",
    "    eps_v_train = train_df['v_score_text'].to_numpy() - linear_eps_v.predict(train_df_protected)\n",
    "    eps_v_test = test_df['v_score_text'].to_numpy() - linear_eps_v.predict(test_df_protected)\n",
    "    \n",
    "\n",
    "    # predict on target using abducted latents\n",
    "    train_eps_stacked = np.hstack((eps_w_train.reshape(-1, 1), eps_e_train.reshape(-1, 1), \n",
    "                                   eps_o_train.reshape(-1, 1), eps_g_train.reshape(-1, 1), \n",
    "                                   eps_l_train.reshape(-1, 1), eps_h_train.reshape(-1, 1), \n",
    "                                   eps_v_train.reshape(-1, 1),\n",
    "                                   train_df['age'].to_numpy().reshape(-1, 1)))\n",
    "    \n",
    "    test_eps_stacked = np.hstack((eps_w_test.reshape(-1, 1), eps_e_test.reshape(-1, 1), \n",
    "                                  eps_o_test.reshape(-1, 1), eps_g_test.reshape(-1, 1), \n",
    "                                  eps_l_test.reshape(-1, 1), eps_h_test.reshape(-1, 1), \n",
    "                                  eps_v_test.reshape(-1, 1),\n",
    "                                  test_df['age'].to_numpy().reshape(-1, 1)))\n",
    "    smlr_L3 = SM_LinearRegression()\n",
    "    smlr_L3.fit(train_eps_stacked, train_df_y)\n",
    "\n",
    "    # predict on test epsilons\n",
    "    preds = smlr_L3.predict(test_eps_stacked)\n",
    "\n",
    "    # Return Results:\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57881ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfair_preds = Unfair_Model_Replication(compas_ds.train_df, compas_ds.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4e5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unaware_preds = Unaware_Model_Replication(compas_ds.train_df, compas_ds.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b49151",
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_preds = L3_Model_Replication(compas_ds.train_df, compas_ds.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad8656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfair RMSE: \t\t\t0.455\n",
      "FTU RMSE: \t\t\t0.456\n",
      "Level 3 (Fair Add) RMSE: \t0.458\n"
     ]
    }
   ],
   "source": [
    "print('Unfair RMSE: \\t\\t\\t%.3f' % np.sqrt(mean_squared_error(unfair_preds, compas_ds.test_df['two_year_recid'])))\n",
    "print('FTU RMSE: \\t\\t\\t%.3f' % np.sqrt(mean_squared_error(unaware_preds, compas_ds.test_df['two_year_recid'])))\n",
    "print('Level 3 (Fair Add) RMSE: \\t%.3f' % np.sqrt(mean_squared_error(l3_preds, compas_ds.test_df['two_year_recid'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfbee66",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd76d53",
   "metadata": {},
   "source": [
    "### Balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7624e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f15187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfair balanced accuracy: \t\t0.670\n",
      "FTU balanced accuracy: \t\t\t0.672\n",
      "Level 3 (Fair Add) balanced accuracy: \t0.659\n"
     ]
    }
   ],
   "source": [
    "target='two_year_recid'\n",
    "print('Unfair balanced accuracy: \\t\\t%.3f' % balanced_accuracy_score(compas_ds.test_df[target], np.array(unfair_preds >= 0.5).astype(int)))\n",
    "print('FTU balanced accuracy: \\t\\t\\t%.3f' % balanced_accuracy_score(compas_ds.test_df[target], np.array(unaware_preds >= 0.5).astype(int)))\n",
    "print('Level 3 (Fair Add) balanced accuracy: \\t%.3f' % balanced_accuracy_score(compas_ds.test_df[target], np.array(l3_preds >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6556868",
   "metadata": {},
   "source": [
    "### Equalized odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b57760",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = compas_ds.test_df.copy()\n",
    "preds_df['unfair'] = np.array(unfair_preds >= 0.5).astype(int)\n",
    "preds_df['unaware'] = np.array(unaware_preds >= 0.5).astype(int)\n",
    "preds_df['l3'] = np.array(l3_preds >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f653a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_odds(preds_df, method='unfair', target='two_year_recid', protected=['sex', 'race']):\n",
    "    \n",
    "    preds_df['binary_age'] = preds_df['age'] >= 0.5\n",
    "    eq_odds = []\n",
    "    for attribute in protected:\n",
    "        eq_odd = preds_df.loc[(preds_df[target]==1) & (preds_df[attribute]==0), method].mean() -  preds_df.loc[(preds_df[target]==1) & (preds_df[attribute]==1), method].mean()\n",
    "        eq_odd += preds_df.loc[(preds_df[target]==0) & (preds_df[attribute]==0), method].mean() -  preds_df.loc[(preds_df[target]==0) & (preds_df[attribute]==1), method].mean()\n",
    "        eq_odds.append(np.abs(eq_odd))\n",
    "    return np.mean(eq_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca83037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfair Equalized Odds score: \t\t\t0.341\n",
      "FTU Equalized Odds score: \t\t\t0.248\n",
      "Level 3 (Fair Add) Equalized Odds score: \t0.112\n"
     ]
    }
   ],
   "source": [
    "print('Unfair Equalized Odds score: \\t\\t\\t%.3f' % equalized_odds(preds_df, method='unfair'))\n",
    "print('FTU Equalized Odds score: \\t\\t\\t%.3f' % equalized_odds(preds_df, method='unaware'))\n",
    "print('Level 3 (Fair Add) Equalized Odds score: \\t%.3f' % equalized_odds(preds_df, method='l3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edef024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
